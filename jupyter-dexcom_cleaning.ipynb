{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb282c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "from google.cloud import storage\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec8b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName('DexcomCleaning') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2256821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set output configuration\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9bae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"maude-device-reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104d721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#View datasets in blob storage\n",
    "gcs_client = storage.Client()\n",
    "bucket = gcs_client.bucket(BUCKET_NAME)\n",
    "\n",
    "list(bucket.list_blobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a14ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data(year):\n",
    "    \n",
    "    text_schema = StructType([\n",
    "        StructField(\"MDR_REPORT_KEY\", IntegerType()),\n",
    "        StructField(\"MDR_TEXT_KEY\", IntegerType()),\n",
    "        StructField(\"TEXT_TYPE_CODE\", StringType()),\n",
    "        StructField(\"PATIENT_SEQUENCE_NUMBER\", IntegerType()),\n",
    "        StructField(\"DATE_REPORT\", DateType()),\n",
    "        StructField(\"FOI_TEXT\", StringType())\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    text_df = spark \\\n",
    "        .read \\\n",
    "        .schema(text_schema) \\\n",
    "        .option(\"header\" , \"true\") \\\n",
    "        .option(\"delimiter\", \"|\") \\\n",
    "        .csv(f\"./foitext{year}.txt\")\n",
    "    \n",
    "    # Replace to this if using in cloud environment: .csv(f\"gs://{BUCKET_NAME}/foitext{year}.txt\")\n",
    "    \n",
    "    return text_df\n",
    "\n",
    "def load_device_data(year):\n",
    "\n",
    "    device_schema = StructType([\n",
    "        StructField(\"MDR_REPORT_KEY\", IntegerType()),\n",
    "        StructField(\"DEVICE_EVENT_KEY\", IntegerType()),\n",
    "        StructField(\"IMPLANT_FLAG\", StringType()),\n",
    "        StructField(\"DATE_REMOVED_FLAG\", DateType()),\n",
    "        StructField(\"DEVICE_SEQUENCE_NO\", IntegerType()),\n",
    "        StructField(\"DATE_RECEIVED\", StringType()), #StructField(\"DATE_RECEIVED\", DateType()),\n",
    "        StructField(\"BRAND_NAME\", StringType()),\n",
    "        StructField(\"GENERIC_NAME\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_NAME\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_ADDRESS_1\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_ADDRESS_2\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_CITY\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_STATE_CODE\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_ZIP_CODE\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_ZIP_CODE_EXT\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_COUNTRY_CODE\", StringType()),\n",
    "        StructField(\"MANUFACTURER_D_POSTAL_CODE\", StringType()),\n",
    "        StructField(\"DEVICE_OPERATOR\", StringType()),\n",
    "        StructField(\"EXPIRATION_DATE_OF_DEVICE\", DateType()),\n",
    "        StructField(\"MODEL_NUMBER\", IntegerType()),\n",
    "        StructField(\"CATALOG_NUMBER\", IntegerType()),\n",
    "        StructField(\"LOT_NUMBER\", IntegerType()),\n",
    "        StructField(\"OTHER_ID_NUMBER\", StringType()),\n",
    "        StructField(\"DEVICE_AVAILABILITY\", StringType()),\n",
    "        StructField(\"DATE_RETURNED_TO_MANUFACTURER\", DateType()),\n",
    "        StructField(\"DEVICE_REPORT_PRODUCT_CODE\", StringType()),\n",
    "        StructField(\"DEVICE_AGE_TEXT\", StringType()),\n",
    "        StructField(\"DEVICE_EVALUATED_BY_MANUFACTUR\", StringType()),\n",
    "        StructField(\"COMBINATION_PRODUCT_FLAG\", StringType())\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    device_df = spark \\\n",
    "        .read \\\n",
    "        .schema(device_schema) \\\n",
    "        .option(\"header\" , \"true\") \\\n",
    "        .option(\"delimiter\", \"|\") \\\n",
    "        .csv(f\"./device{year}.txt\")\n",
    "    \n",
    "    ## Replace to this if using in cloud environment: .csv(f\"gs://{BUCKET_NAME}/device{year}.txt\")\n",
    "    \n",
    "    return device_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220e684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text16 = load_text_data(2016)\n",
    "text17 = load_text_data(2017)\n",
    "text18 = load_text_data(2018)\n",
    "text19 = load_text_data(2019)\n",
    "text20 = load_text_data(2020)\n",
    "text21 = load_text_data(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c45100d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device16 = load_device_data(2016)\n",
    "device17 = load_device_data(2017)\n",
    "device18 = load_device_data(2018)\n",
    "device19 = load_device_data(2019)\n",
    "device20 = load_device_data(2020)\n",
    "device21 = load_device_data(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b5da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(*dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c276e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_all = unionAll(text16, text17, text18, text19, text20, text21) #16802162 records\n",
    "device_all = unionAll(device16, device17, device18, device19, device20, device21) #7790750 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2033c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Temp tables for device and text\n",
    "text_all.createOrReplaceTempView(\"text_tbl\")\n",
    "device_all.createOrReplaceTempView(\"device_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "914423b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dexcom_reports_query = \"\"\"\n",
    "    SELECT \n",
    "        device.MDR_REPORT_KEY,\n",
    "        to_date(device.DATE_RECEIVED,'yyyy/mm/dd') as DATE_RECEIVED,\n",
    "        device.BRAND_NAME,\n",
    "        device.GENERIC_NAME,\n",
    "        device.MANUFACTURER_D_NAME,\n",
    "        text.FOI_TEXT\n",
    "    FROM text_tbl AS text \n",
    "    LEFT JOIN device_tbl AS device \n",
    "    ON text.MDR_REPORT_KEY ==  device.MDR_REPORT_KEY\n",
    "    WHERE text.TEXT_TYPE_CODE = 'D' AND device.BRAND_NAME LIKE '%DEXCOM%'\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b001c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dexcom_df = spark.sql(dexcom_reports_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5353f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export one file locally\n",
    "dexcom_df.coalesce(1).write.csv(\"dexcom_reports_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7164c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export one file to bucket\n",
    "#all_filepath = f\"gs://{BUCKET_NAME}/reports_all.csv\"\n",
    "dexcom_filepath = f\"gs://{BUCKET_NAME}/dexcom_reports_all.csv\"\n",
    "\n",
    "#reports_all.write.mode('overwrite').csv(all_filepath)\n",
    "dexcom_df.coalesce(1).write.mode('overwrite').csv(dexcom_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94ef49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f9646f5fe092bd252f3383a2398620ba16a24c6a6b486a4f3d8bb34b7887ce7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
